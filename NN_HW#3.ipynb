{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3b-oF2KrmHT",
        "outputId": "f60e52f6-aaef-4798-acc1-8a2da0a308df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "!pip install rouge\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZOExDjBmWJN",
        "outputId": "e8cafae2-be23-4061-c2e3-31e1970738bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing test perplexity...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing perplexity: 100%|██████████| 349/349 [00:12<00:00, 27.66it/s, perplexity=642265138055408000.00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Perplexity: 642265138055408000.00\n",
            "\n",
            "Computing BLEU and ROUGE scores...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating samples: 100%|██████████| 100/100 [00:34<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Test Results:\n",
            "Perplexity: 642265138055408000.00\n",
            "BLEU-1: 0.0000\n",
            "BLEU-2: 0.0000\n",
            "BLEU-3: 0.0000\n",
            "BLEU-4: 0.0000\n",
            "\n",
            "ROUGE Scores:\n",
            "rouge-1: F1=0.0000 R=0.0000 P=0.0000\n",
            "rouge-2: F1=0.0000 R=0.0000 P=0.0000\n",
            "rouge-l: F1=0.0000 R=0.0000 P=0.0000\n",
            "\n",
            "Example Text Generation:\n",
            "Prompt: Cymbeline: But Ajax is their fool.\n",
            "Generated continuation: Cymbeline: But Ajax is their fool.....................................................................................................\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "from transformers import GPT2Tokenizer\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from rouge import Rouge\n",
        "import random\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# ---------------------------\n",
        "# Data Loading and Preprocessing\n",
        "# ---------------------------\n",
        "\n",
        "# Load the dataset\n",
        "data_path = 'shakespeare.csv'\n",
        "if not os.path.exists(data_path):\n",
        "    raise FileNotFoundError(f\"The file {data_path} does not exist in the current directory.\")\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Preprocessing\n",
        "lines_df = df[df['PlayerLine'].notna()].copy()\n",
        "play_titles = df[df['Player'].isna()]['Play'].unique()\n",
        "\n",
        "# Create corpus\n",
        "corpus = []\n",
        "current_play = None\n",
        "for _, row in df.iterrows():\n",
        "    if pd.isna(row['Player']):\n",
        "        if row['PlayerLine'] is not None and (row['PlayerLine'].startswith(\"ACT\") or row['PlayerLine'].startswith(\"SCENE\")):\n",
        "            continue\n",
        "        else:\n",
        "            current_play = row['Play']\n",
        "    elif pd.notna(row['PlayerLine']):\n",
        "        corpus.append({\n",
        "            'Play': current_play,\n",
        "            'Player': row['Player'],\n",
        "            'Line': row['PlayerLine']\n",
        "        })\n",
        "\n",
        "# ---------------------------\n",
        "# Model Architecture\n",
        "# ---------------------------\n",
        "\n",
        "class LayerNormCustom(nn.Module):\n",
        "    def __init__(self, hidden_dim, eps=1e-5):\n",
        "        super(LayerNormCustom, self).__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(hidden_dim))\n",
        "        self.beta = nn.Parameter(torch.zeros(hidden_dim))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, unbiased=False, keepdim=True)\n",
        "        normalized = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.gamma * normalized + self.beta\n",
        "\n",
        "class SinusoidalPositionalEncoding(nn.Module):\n",
        "    def __init__(self, hidden_dim, max_len=5000):\n",
        "        super(SinusoidalPositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, hidden_dim)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, hidden_dim, 2).float() * (-math.log(10000.0) / hidden_dim))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1), :]\n",
        "\n",
        "class MultiHeadAttentionCustom(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_heads):\n",
        "        super(MultiHeadAttentionCustom, self).__init__()\n",
        "        assert hidden_dim % num_heads == 0\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = hidden_dim // num_heads\n",
        "\n",
        "        self.W_q = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
        "        self.W_k = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
        "        self.W_v = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
        "        self.W_o = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
        "\n",
        "        nn.init.xavier_uniform_(self.W_q)\n",
        "        nn.init.xavier_uniform_(self.W_k)\n",
        "        nn.init.xavier_uniform_(self.W_v)\n",
        "        nn.init.xavier_uniform_(self.W_o)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_length, hidden_dim = x.size()\n",
        "\n",
        "        Q = torch.matmul(x, self.W_q)\n",
        "        K = torch.matmul(x, self.W_k)\n",
        "        V = torch.matmul(x, self.W_v)\n",
        "\n",
        "        Q = Q.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1,2)\n",
        "        K = K.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1,2)\n",
        "        V = V.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1,2)\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "        mask = torch.tril(torch.ones(seq_length, seq_length)).to(x.device)\n",
        "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "        context = torch.matmul(attn, V)\n",
        "        context = context.transpose(1,2).contiguous().view(batch_size, seq_length, hidden_dim)\n",
        "        out = torch.matmul(context, self.W_o)\n",
        "\n",
        "        return out\n",
        "\n",
        "class FeedForwardNetwork(nn.Module):\n",
        "    def __init__(self, hidden_dim, ff_dim, activation=F.relu):\n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(hidden_dim, ff_dim)\n",
        "        self.fc2 = nn.Linear(ff_dim, hidden_dim)\n",
        "        self.activation = activation\n",
        "\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.zeros_(self.fc1.bias)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.zeros_(self.fc2.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.activation(self.fc1(x)))\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_heads, ff_dim):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.ln1 = LayerNormCustom(hidden_dim)\n",
        "        self.mha = MultiHeadAttentionCustom(hidden_dim, num_heads)\n",
        "        self.ln2 = LayerNormCustom(hidden_dim)\n",
        "        self.ffn = FeedForwardNetwork(hidden_dim, ff_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_norm = self.ln1(x)\n",
        "        attn_out = self.mha(x_norm)\n",
        "        x = x + attn_out\n",
        "\n",
        "        x_norm = self.ln2(x)\n",
        "        ffn_out = self.ffn(x_norm)\n",
        "        x = x + ffn_out\n",
        "\n",
        "        return x\n",
        "\n",
        "class DecoderOnlyTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_dim=384, num_layers=6, num_heads=6, ff_dim=1536, max_seq_length=512):\n",
        "        super(DecoderOnlyTransformer, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.token_embedding = nn.Embedding(vocab_size, hidden_dim)\n",
        "        self.positional_encoding = SinusoidalPositionalEncoding(hidden_dim, max_len=max_seq_length)\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerBlock(hidden_dim, num_heads, ff_dim) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.ln_f = LayerNormCustom(hidden_dim)\n",
        "        self.lm_head = nn.Linear(hidden_dim, vocab_size, bias=False)\n",
        "        self.lm_head.weight = self.token_embedding.weight\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.token_embedding(input_ids)\n",
        "        x = self.positional_encoding(x)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "# ---------------------------\n",
        "# Dataset and DataLoader\n",
        "# ---------------------------\n",
        "\n",
        "class ShakespeareDataset(Dataset):\n",
        "    def __init__(self, encoded_corpus, block_size):\n",
        "        self.block_size = block_size\n",
        "        self.data = []\n",
        "\n",
        "        for line in encoded_corpus:\n",
        "            if len(line) < 2:\n",
        "                continue\n",
        "\n",
        "            if len(line) > block_size:\n",
        "                line = line[:block_size]\n",
        "            else:\n",
        "                padding = [subword_tokenizer.pad_token_id] * (block_size - len(line))\n",
        "                line = line + padding\n",
        "\n",
        "            inputs = line[:-1]\n",
        "            targets = line[1:]\n",
        "\n",
        "            self.data.append((inputs, targets))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs, targets = self.data[idx]\n",
        "        return torch.tensor(inputs, dtype=torch.long), torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "# ---------------------------\n",
        "# Training Utils\n",
        "# ---------------------------\n",
        "\n",
        "def compute_perplexity_with_progress(model, data_loader, device):\n",
        "    model.eval()\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    total_loss = 0.0\n",
        "    total_tokens = 0\n",
        "\n",
        "    val_bar = tqdm(data_loader, desc='Computing perplexity',\n",
        "                  position=0, leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_bar:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            outputs = outputs.view(-1, outputs.size(-1))\n",
        "            targets = targets.view(-1)\n",
        "\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            total_loss += loss.item() * targets.size(0)\n",
        "            total_tokens += targets.size(0)\n",
        "\n",
        "            current_perplexity = math.exp(total_loss / total_tokens)\n",
        "            val_bar.set_postfix({'perplexity': f'{current_perplexity:.2f}'})\n",
        "\n",
        "    avg_loss = total_loss / total_tokens\n",
        "    return math.exp(avg_loss)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, device, learning_rate=3e-4):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    best_val_perplexity = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}',\n",
        "                        position=0, leave=True)\n",
        "\n",
        "        for inputs, targets in train_bar:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            outputs = outputs.view(-1, outputs.size(-1))\n",
        "            targets = targets.view(-1)\n",
        "\n",
        "            loss = nn.CrossEntropyLoss()(outputs, targets)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            train_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "        val_perplexity = compute_perplexity_with_progress(model, val_loader, device)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
        "        print(f\"Average Loss: {avg_epoch_loss:.4f}\")\n",
        "        print(f\"Validation Perplexity: {val_perplexity:.2f}\")\n",
        "\n",
        "        if val_perplexity < best_val_perplexity:\n",
        "            best_val_perplexity = val_perplexity\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(f\"New best model saved! (Perplexity: {val_perplexity:.2f})\")\n",
        "        print()\n",
        "\n",
        "def generate_continuation(model, tokenizer, prompt_ids, max_length=100, context_size=256,\n",
        "                           sampling_strategy='greedy', top_k=50, device='cpu'):\n",
        "    model.eval()\n",
        "    input_ids = torch.tensor([prompt_ids], dtype=torch.long).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_length):\n",
        "            if input_ids.size(1) > context_size:\n",
        "                input_ids = input_ids[:, -context_size:]\n",
        "\n",
        "            logits = model(input_ids)\n",
        "            next_token_logits = logits[0, -1, :]\n",
        "\n",
        "            if sampling_strategy == 'greedy':\n",
        "                next_token = torch.argmax(next_token_logits).unsqueeze(0).unsqueeze(0)\n",
        "            elif sampling_strategy == 'top_k':\n",
        "                top_k = min(top_k, next_token_logits.size(-1))\n",
        "                topk_logits, topk_indices = torch.topk(next_token_logits, top_k)\n",
        "                probs = F.softmax(topk_logits, dim=-1)\n",
        "                next_token_idx = torch.multinomial(probs, num_samples=1)\n",
        "                next_token = topk_indices[next_token_idx].unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
        "\n",
        "            if next_token.item() == tokenizer.eos_token_id:\n",
        "                break\n",
        "            if input_ids.size(1) >= 1024:\n",
        "                break\n",
        "\n",
        "    return input_ids.squeeze().tolist()\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download(['punkt', 'punkt_tab', 'averaged_perceptron_tagger'])\n",
        "\n",
        "def evaluate_model(model, test_data, tokenizer, num_samples=100, device='cpu'):\n",
        "    selected_samples = random.sample(test_data, num_samples)\n",
        "    reference_texts = []\n",
        "    candidate_texts = []\n",
        "\n",
        "    for sample in tqdm(selected_samples, desc=\"Generating samples\"):\n",
        "        prompt_length = min(10, len(sample)-1)\n",
        "        if prompt_length < 1:\n",
        "            continue\n",
        "\n",
        "        prompt = sample[:prompt_length]\n",
        "        ground_truth = sample[prompt_length:]\n",
        "\n",
        "        generated_ids = generate_continuation(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            prompt_ids=prompt,\n",
        "            max_length=50,  # Limit generation length\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        # Decode texts, ensuring non-empty outputs\n",
        "        generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
        "        ground_truth_text = tokenizer.decode(ground_truth, skip_special_tokens=True).strip()\n",
        "\n",
        "        if generated_text and ground_truth_text:\n",
        "            reference_texts.append([generated_text.lower().split()])\n",
        "            candidate_texts.append(ground_truth_text.lower().split())\n",
        "\n",
        "    if len(reference_texts) == 0 or len(candidate_texts) == 0:\n",
        "        print(\"No valid text pairs generated\")\n",
        "        return [0.0] * 4, {'rouge-1': {'f': 0.0, 'p': 0.0, 'r': 0.0}}\n",
        "\n",
        "    # Calculate BLEU scores\n",
        "    smooth = SmoothingFunction().method4\n",
        "    bleu_weights = [(1,0,0,0), (0.5,0.5,0,0), (0.33,0.33,0.33,0), (0.25,0.25,0.25,0.25)]\n",
        "    bleu_scores = []\n",
        "\n",
        "    for weight in bleu_weights:\n",
        "        try:\n",
        "            score = corpus_bleu(reference_texts, candidate_texts, weights=weight, smoothing_function=smooth)\n",
        "            bleu_scores.append(score)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating BLEU score: {str(e)}\")\n",
        "            bleu_scores.append(0.0)\n",
        "\n",
        "    # Calculate ROUGE scores\n",
        "    try:\n",
        "        rouge = Rouge()\n",
        "        rouge_scores = rouge.get_scores(' '.join(candidate_texts[0]), ' '.join(reference_texts[0][0]), avg=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating ROUGE score: {str(e)}\")\n",
        "        rouge_scores = {'rouge-1': {'f': 0.0, 'p': 0.0, 'r': 0.0}}\n",
        "\n",
        "    return bleu_scores, rouge_scores\n",
        "\n",
        "class CharTokenizer:\n",
        "    def __init__(self):\n",
        "        # Define basic vocabulary with printable characters\n",
        "        self.vocab = sorted(list(string.printable))\n",
        "\n",
        "        # Add special tokens\n",
        "        self.special_tokens = ['[PAD]', '[BOS]', '[EOS]', '[UNK]']\n",
        "        self.vocab.extend(self.special_tokens)\n",
        "\n",
        "        # Create bidirectional mappings\n",
        "        self.char2idx = {char: idx for idx, char in enumerate(self.vocab)}\n",
        "        self.idx2char = {idx: char for idx, char in enumerate(self.vocab)}\n",
        "\n",
        "        # Define special token IDs\n",
        "        self.pad_token = '[PAD]'\n",
        "        self.bos_token = '[BOS]'\n",
        "        self.eos_token = '[EOS]'\n",
        "        self.unk_token = '[UNK]'\n",
        "\n",
        "        self.pad_token_id = self.char2idx[self.pad_token]\n",
        "        self.bos_token_id = self.char2idx[self.bos_token]\n",
        "        self.eos_token_id = self.char2idx[self.eos_token]\n",
        "        self.unk_token_id = self.char2idx[self.unk_token]\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the vocabulary size\"\"\"\n",
        "        return len(self.vocab)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"Convert text to list of tokens\"\"\"\n",
        "        return [self.bos_token] + list(text) + [self.eos_token]\n",
        "\n",
        "    def encode(self, text, add_special_tokens=True):\n",
        "        \"\"\"Convert text to token IDs\"\"\"\n",
        "        if add_special_tokens:\n",
        "            tokens = self.tokenize(text)\n",
        "        else:\n",
        "            tokens = list(text)\n",
        "        return [self.char2idx.get(char, self.unk_token_id) for char in tokens]\n",
        "\n",
        "    def decode(self, ids, skip_special_tokens=True):\n",
        "        \"\"\"Convert token IDs back to text\"\"\"\n",
        "        tokens = [self.idx2char[idx] for idx in ids]\n",
        "        if skip_special_tokens:\n",
        "            tokens = [t for t in tokens if t not in self.special_tokens]\n",
        "        return ''.join(tokens)\n",
        "\n",
        "class ShakespeareDataset(Dataset):\n",
        "    \"\"\"A PyTorch Dataset for Shakespeare text data that supports both character-level\n",
        "    and subword tokenization schemes.\"\"\"\n",
        "\n",
        "    def __init__(self, encoded_sequences, block_size):\n",
        "        \"\"\"Initialize the dataset with encoded sequences and parameters.\n",
        "\n",
        "        Args:\n",
        "            encoded_sequences: List of token sequences (already encoded by appropriate tokenizer)\n",
        "            block_size: Maximum sequence length for training\n",
        "        \"\"\"\n",
        "        self.block_size = block_size\n",
        "        self.data = []\n",
        "\n",
        "        # Process each sequence into overlapping chunks\n",
        "        for sequence in encoded_sequences:\n",
        "            # Skip sequences that are too short\n",
        "            if len(sequence) < 2:\n",
        "                continue\n",
        "\n",
        "            # Prepare the sequence\n",
        "            if len(sequence) > block_size + 1:\n",
        "                # If sequence is too long, create multiple training examples\n",
        "                for i in range(0, len(sequence) - block_size):\n",
        "                    chunk = sequence[i:i + block_size + 1]\n",
        "                    self.data.append(chunk)\n",
        "            else:\n",
        "                # If sequence is shorter than block_size, pad it\n",
        "                padding_needed = (block_size + 1) - len(sequence)\n",
        "                padded_sequence = sequence + [0] * padding_needed  # Use 0 as padding token\n",
        "                self.data.append(padded_sequence)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of sequences in the dataset.\"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Get a single training example.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (input_sequence, target_sequence) where target_sequence is input_sequence\n",
        "                  shifted one position to the right\n",
        "        \"\"\"\n",
        "        chunk = self.data[idx]\n",
        "        x = torch.tensor(chunk[:-1], dtype=torch.long)  # Input sequence\n",
        "        y = torch.tensor(chunk[1:], dtype=torch.long)   # Target sequence\n",
        "        return x, y\n",
        "    \n",
        "class CharTokenizer:\n",
        "    def __init__(self):\n",
        "        # Define vocabulary: printable chars plus special tokens\n",
        "        self.vocab = sorted(list(string.printable)) + ['[BOS]', '[EOS]', '[PAD]']\n",
        "\n",
        "        # Create bidirectional mappings between characters and indices\n",
        "        self.char2idx = {char: idx for idx, char in enumerate(self.vocab)}\n",
        "        self.idx2char = {idx: char for idx, char in enumerate(self.vocab)}\n",
        "\n",
        "        # Define special tokens\n",
        "        self.bos_token = '[BOS]'\n",
        "        self.eos_token = '[EOS]'\n",
        "        self.pad_token = '[PAD]'\n",
        "\n",
        "        # Store token IDs for easy access\n",
        "        self.bos_token_id = self.char2idx[self.bos_token]\n",
        "        self.eos_token_id = self.char2idx[self.eos_token]\n",
        "        self.pad_token_id = self.char2idx[self.pad_token]\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return vocabulary size\"\"\"\n",
        "        return len(self.vocab)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"Convert text to sequence of tokens including special tokens\"\"\"\n",
        "        return [self.bos_token] + list(text) + [self.eos_token]\n",
        "\n",
        "    def encode(self, text):\n",
        "        \"\"\"Convert text to sequence of token IDs\"\"\"\n",
        "        return [self.char2idx.get(char, self.char2idx[' ']) for char in self.tokenize(text)]\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        \"\"\"Convert sequence of token IDs back to text, removing special tokens\"\"\"\n",
        "        chars = [self.idx2char.get(idx, ' ') for idx in tokens]\n",
        "        # Remove special tokens from output\n",
        "        text = ''.join(char for char in chars\n",
        "                      if char not in [self.bos_token, self.eos_token, self.pad_token])\n",
        "        return text\n",
        "\n",
        "    def batch_encode(self, texts, max_length=None, padding=True):\n",
        "        \"\"\"Encode a batch of texts with optional padding\"\"\"\n",
        "        encoded = [self.encode(text) for text in texts]\n",
        "\n",
        "        if padding and max_length:\n",
        "            # Pad all sequences to max_length\n",
        "            encoded = [seq[:max_length] + [self.pad_token_id] * (max_length - len(seq))\n",
        "                      for seq in encoded]\n",
        "\n",
        "        return encoded\n",
        "\n",
        "# ---------------------------\n",
        "# Main Execution\n",
        "# ---------------------------\n",
        "\n",
        "# Initialize tokenizer\n",
        "subword_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "char_tokenizer = CharTokenizer()\n",
        "special_tokens = {'pad_token': '[PAD]', 'bos_token': '[BOS]', 'eos_token': '[EOS]'}\n",
        "subword_tokenizer.add_special_tokens(special_tokens)\n",
        "\n",
        "# Prepare data\n",
        "for entry in corpus:\n",
        "    entry['LineWithPlay'] = f\"{entry['Play']}: {entry['Line']}\"\n",
        "\n",
        "# Encode corpus\n",
        "corpus_subword_encoded = [subword_tokenizer.encode(entry['LineWithPlay'], add_special_tokens=True)\n",
        "                         for entry in corpus]\n",
        "\n",
        "# Split data\n",
        "train_data, test_data = train_test_split(corpus_subword_encoded, test_size=0.1, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.1111, random_state=42)\n",
        "\n",
        "# Create datasets\n",
        "block_size = 50\n",
        "train_dataset = ShakespeareDataset(train_data, block_size)\n",
        "val_dataset = ShakespeareDataset(val_data, block_size)\n",
        "test_dataset = ShakespeareDataset(test_data, block_size)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Initialize model\n",
        "vocab_size = len(subword_tokenizer)\n",
        "model = DecoderOnlyTransformer(vocab_size=vocab_size)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Train model\n",
        "num_epochs = 1\n",
        "train_model(model, train_loader, val_loader, num_epochs, device)\n",
        "\n",
        "# Evaluate model\n",
        "print(\"Computing test perplexity...\")\n",
        "test_perplexity = compute_perplexity_with_progress(model, test_loader, device)\n",
        "print(f\"\\nTest Perplexity: {test_perplexity:.2f}\\n\")\n",
        "\n",
        "print(\"Computing BLEU and ROUGE scores...\")\n",
        "bleu_scores, rouge_scores = evaluate_model(model, test_data, subword_tokenizer, device=device)\n",
        "\n",
        "# Print final results\n",
        "print(\"\\nFinal Test Results:\")\n",
        "print(f\"Perplexity: {test_perplexity:.2f}\")\n",
        "for i, score in enumerate(bleu_scores, 1):\n",
        "    print(f\"BLEU-{i}: {score:.4f}\")\n",
        "print(\"\\nROUGE Scores:\")\n",
        "for metric, scores in rouge_scores.items():\n",
        "    print(f\"{metric}: F1={scores['f']:.4f} R={scores['r']:.4f} P={scores['p']:.4f}\")\n",
        "\n",
        "# Example text generation\n",
        "print(\"\\nExample Text Generation:\")\n",
        "sample_prompt = test_data[0][:10]  # Take first 10 tokens of first test sample\n",
        "prompt_text = subword_tokenizer.decode(sample_prompt)\n",
        "print(f\"Prompt: {prompt_text}\")\n",
        "\n",
        "generated_ids = generate_continuation(model, subword_tokenizer, sample_prompt, device=device)\n",
        "generated_text = subword_tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
        "print(f\"Generated continuation: {generated_text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGofpMt-1DDv",
        "outputId": "9c1e2358-b1aa-4d4f-976e-07381aa8d496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Running experiment: small model with char tokenization\n",
            "\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 1484/1484 [01:58<00:00, 12.57it/s, loss=0.6352, ppl=6.33, lr=1.61e-09]\n",
            "Validating: 100%|██████████| 183/183 [00:04<00:00, 37.82it/s]\n",
            "<ipython-input-29-9ae72fc82667>:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(os.path.join(tracker.save_dir, f\"{tracker.experiment_id}_best.pth\")))\n",
            "Validating: 100%|██████████| 202/202 [00:05<00:00, 35.62it/s]\n",
            "Generating samples: 100%|██████████| 100/100 [00:22<00:00,  4.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running experiment: small model with subword tokenization\n",
            "\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 1396/1396 [06:48<00:00,  3.42it/s, loss=0.5761, ppl=3.34, lr=1.67e-09]\n",
            "Validating: 100%|██████████| 175/175 [00:17<00:00,  9.81it/s]\n",
            "Validating: 100%|██████████| 176/176 [00:18<00:00,  9.76it/s]\n",
            "Generating samples: 100%|██████████| 100/100 [00:24<00:00,  4.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running experiment: large model with char tokenization\n",
            "\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 1484/1484 [10:30<00:00,  2.35it/s, loss=0.5343, ppl=5.70, lr=1.61e-09]\n",
            "Validating: 100%|██████████| 183/183 [00:25<00:00,  7.11it/s]\n",
            "Validating: 100%|██████████| 202/202 [00:28<00:00,  7.10it/s]\n",
            "Generating samples: 100%|██████████| 100/100 [00:40<00:00,  2.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running experiment: large model with subword tokenization\n",
            "\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 1396/1396 [18:20<00:00,  1.27it/s, loss=0.7977, ppl=3.42, lr=1.67e-09]\n",
            "Validating: 100%|██████████| 175/175 [00:45<00:00,  3.82it/s]\n",
            "Validating: 100%|██████████| 176/176 [00:46<00:00,  3.81it/s]\n",
            "Generating samples: 100%|██████████| 100/100 [00:44<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error calculating ROUGE score: Hypothesis is empty.\n",
            "\n",
            "Final Results Summary\n",
            "==================================================\n",
            "\n",
            "Small Model with char tokenization:\n",
            "Test Perplexity: 2.24\n",
            "BLEU-1: 0.0235\n",
            "ROUGE-1 F1: 0.0000\n",
            "\n",
            "Sample Generation:\n",
            "Prompt: Cymbeline\n",
            "Target: : Here come those I have done good to against my will,\n",
            "Generated: Cymbeline: The see the seee the see the seee the stay seent\n",
            "\n",
            "Small Model with subword tokenization:\n",
            "Test Perplexity: 2.02\n",
            "BLEU-1: 0.0153\n",
            "ROUGE-1 F1: 0.0000\n",
            "\n",
            "Sample Generation:\n",
            "Prompt: Cymbeline: As index to the story we\n",
            "Target:  late talk'd of,\n",
            "Generated: Cymbeline: As index to the story we,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
            "\n",
            "Large Model with char tokenization:\n",
            "Test Perplexity: 2.07\n",
            "BLEU-1: 0.0218\n",
            "ROUGE-1 F1: 0.0000\n",
            "\n",
            "Sample Generation:\n",
            "Prompt: Cymbeline\n",
            "Target: : Hear me, my love: be thou but true of heart,--\n",
            "Generated: Cymbeline: The shall the stand the world the stand the words,\n",
            "\n",
            "Large Model with subword tokenization:\n",
            "Test Perplexity: 1.96\n",
            "BLEU-1: 0.0138\n",
            "ROUGE-1 F1: 0.0000\n",
            "\n",
            "Sample Generation:\n",
            "Prompt: Cymbeline: Who's there\n",
            "Target: ?\n",
            "Generated: Cymbeline: Who's there is a man, and I'll be!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Configuration dictionaries\n",
        "model_configs = {\n",
        "    'small': {\n",
        "        'hidden_dim': 256,\n",
        "        'num_layers': 4,\n",
        "        'num_heads': 4,\n",
        "        'ff_dim': 1024,\n",
        "        'dropout': 0.1\n",
        "    },\n",
        "    'large': {\n",
        "        'hidden_dim': 512,\n",
        "        'num_layers': 8,\n",
        "        'num_heads': 8,\n",
        "        'ff_dim': 2048,\n",
        "        'dropout': 0.1\n",
        "    }\n",
        "}\n",
        "\n",
        "training_params = {\n",
        "    'batch_size': 64,\n",
        "    'num_epochs': 5,  \n",
        "    'learning_rate': 3e-4,\n",
        "    'warmup_steps': 1000,\n",
        "    'max_steps': 50000,\n",
        "    'gradient_clip_val': 1.0,\n",
        "    'block_size': 128,\n",
        "    'early_stopping_patience': 3\n",
        "}\n",
        "\n",
        "class ExperimentTracker:\n",
        "    def __init__(self, model_size, tokenization_scheme, save_dir='experiments'):\n",
        "        self.model_size = model_size\n",
        "        self.tokenization_scheme = tokenization_scheme\n",
        "        self.save_dir = save_dir\n",
        "        self.experiment_id = f\"{model_size}_{tokenization_scheme}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "        # Create save directory\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        # Initialize metrics\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.train_perplexities = []\n",
        "        self.val_perplexities = []\n",
        "        self.learning_rates = []\n",
        "        self.test_metrics = None\n",
        "        self.samples = []\n",
        "        self.best_val_perplexity = float('inf')\n",
        "        self.epochs_without_improvement = 0\n",
        "\n",
        "    def update_train(self, train_loss, train_perp, val_loss, val_perp, lr):\n",
        "        self.train_losses.append(train_loss)\n",
        "        self.val_losses.append(val_loss)\n",
        "        self.train_perplexities.append(train_perp)\n",
        "        self.val_perplexities.append(val_perp)\n",
        "        self.learning_rates.append(lr)\n",
        "\n",
        "        # Check for improvement\n",
        "        if val_perp < self.best_val_perplexity:\n",
        "            self.best_val_perplexity = val_perp\n",
        "            self.epochs_without_improvement = 0\n",
        "            return True  # Signal to save model\n",
        "        else:\n",
        "            self.epochs_without_improvement += 1\n",
        "            return False\n",
        "\n",
        "    def should_stop_early(self):\n",
        "        return self.epochs_without_improvement >= training_params['early_stopping_patience']\n",
        "\n",
        "    def add_test_metrics(self, perplexity, bleu_scores, rouge_scores):\n",
        "        self.test_metrics = {\n",
        "            'perplexity': perplexity,\n",
        "            'bleu_scores': bleu_scores,\n",
        "            'rouge_scores': rouge_scores\n",
        "        }\n",
        "\n",
        "    def add_sample(self, prompt, target, generated):\n",
        "        self.samples.append({\n",
        "            'prompt': prompt,\n",
        "            'target': target,\n",
        "            'generated': generated\n",
        "        })\n",
        "\n",
        "    def save(self):\n",
        "        save_path = os.path.join(self.save_dir, f\"{self.experiment_id}.json\")\n",
        "        data = {\n",
        "            'model_size': self.model_size,\n",
        "            'tokenization_scheme': self.tokenization_scheme,\n",
        "            'training': {\n",
        "                'train_losses': self.train_losses,\n",
        "                'val_losses': self.val_losses,\n",
        "                'train_perplexities': self.train_perplexities,\n",
        "                'val_perplexities': self.val_perplexities,\n",
        "                'learning_rates': self.learning_rates\n",
        "            },\n",
        "            'test_metrics': self.test_metrics,\n",
        "            'samples': self.samples\n",
        "        }\n",
        "        with open(save_path, 'w') as f:\n",
        "            json.dump(data, f, indent=2)\n",
        "\n",
        "def train_epoch(model, train_loader, optimizer, scheduler, device, vocab_size):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_tokens = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc='Training')\n",
        "    for inputs, targets in progress_bar:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        outputs = outputs.view(-1, vocab_size)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        loss = F.cross_entropy(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), training_params['gradient_clip_val'])\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        total_loss += loss.item() * targets.size(0)\n",
        "        total_tokens += targets.size(0)\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'ppl': f'{math.exp(total_loss/total_tokens):.2f}',\n",
        "            'lr': f'{current_lr:.2e}'\n",
        "        })\n",
        "\n",
        "    avg_loss = total_loss / total_tokens\n",
        "    perplexity = math.exp(avg_loss)\n",
        "    return avg_loss, perplexity, current_lr\n",
        "\n",
        "def validate(model, val_loader, device, vocab_size):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_tokens = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(val_loader, desc='Validating'):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            outputs = outputs.view(-1, vocab_size)\n",
        "            targets = targets.view(-1)\n",
        "\n",
        "            loss = F.cross_entropy(outputs, targets)\n",
        "            total_loss += loss.item() * targets.size(0)\n",
        "            total_tokens += targets.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_tokens\n",
        "    perplexity = math.exp(avg_loss)\n",
        "    return avg_loss, perplexity\n",
        "\n",
        "def run_experiment(model_size, tokenization_scheme, data_splits, device):\n",
        "    print(f\"\\nRunning experiment: {model_size} model with {tokenization_scheme} tokenization\")\n",
        "\n",
        "    # Initialize experiment tracker\n",
        "    tracker = ExperimentTracker(model_size, tokenization_scheme)\n",
        "\n",
        "    # Get data\n",
        "    train_data = data_splits[tokenization_scheme]['train']\n",
        "    val_data = data_splits[tokenization_scheme]['val']\n",
        "    test_data = data_splits[tokenization_scheme]['test']\n",
        "\n",
        "    # Create datasets and dataloaders\n",
        "    train_dataset = ShakespeareDataset(train_data, training_params['block_size'])\n",
        "    val_dataset = ShakespeareDataset(val_data, training_params['block_size'])\n",
        "    test_dataset = ShakespeareDataset(test_data, training_params['block_size'])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=training_params['batch_size'], shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=training_params['batch_size'])\n",
        "    test_loader = DataLoader(test_dataset, batch_size=training_params['batch_size'])\n",
        "\n",
        "    # Initialize model\n",
        "    config = model_configs[model_size]\n",
        "    vocab_size = len(char_tokenizer if tokenization_scheme == 'char' else subword_tokenizer)\n",
        "\n",
        "    model = DecoderOnlyTransformer(\n",
        "        vocab_size=vocab_size,\n",
        "        hidden_dim=config['hidden_dim'],\n",
        "        num_layers=config['num_layers'],\n",
        "        num_heads=config['num_heads'],\n",
        "        ff_dim=config['ff_dim']\n",
        "    ).to(device)\n",
        "\n",
        "    # Initialize optimizer and scheduler\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=training_params['learning_rate'])\n",
        "    num_training_steps = len(train_loader) * training_params['num_epochs']\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=training_params['learning_rate'],\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        epochs=training_params['num_epochs'],\n",
        "        pct_start=0.1\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(training_params['num_epochs']):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{training_params['num_epochs']}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_ppl, current_lr = train_epoch(\n",
        "            model, train_loader, optimizer, scheduler, device, vocab_size\n",
        "        )\n",
        "\n",
        "        # Validate\n",
        "        val_loss, val_ppl = validate(model, val_loader, device, vocab_size)\n",
        "\n",
        "        # Update tracker\n",
        "        should_save = tracker.update_train(train_loss, train_ppl, val_loss, val_ppl, current_lr)\n",
        "\n",
        "        # Save best model\n",
        "        if should_save:\n",
        "            model_path = os.path.join(tracker.save_dir, f\"{tracker.experiment_id}_best.pth\")\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "        # Early stopping check\n",
        "        if tracker.should_stop_early():\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    # Load best model for evaluation\n",
        "    model.load_state_dict(torch.load(os.path.join(tracker.save_dir, f\"{tracker.experiment_id}_best.pth\")))\n",
        "\n",
        "    # Test evaluation\n",
        "    test_loss, test_ppl = validate(model, test_loader, device, vocab_size)\n",
        "    bleu_scores, rouge_scores = evaluate_model(\n",
        "        model, test_data,\n",
        "        char_tokenizer if tokenization_scheme == 'char' else subword_tokenizer,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    tracker.add_test_metrics(test_ppl, bleu_scores, rouge_scores)\n",
        "\n",
        "    # Generate samples\n",
        "    generate_samples(model, test_data, tracker, tokenization_scheme, device)\n",
        "\n",
        "    # Save results\n",
        "    tracker.save()\n",
        "    return tracker\n",
        "\n",
        "def generate_samples(model, test_data, tracker, tokenization_scheme, device, num_samples=5):\n",
        "    tokenizer = char_tokenizer if tokenization_scheme == 'char' else subword_tokenizer\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        sample_idx = random.randint(0, len(test_data)-1)\n",
        "        sample = test_data[sample_idx]\n",
        "        prompt_length = min(10, len(sample)-1)\n",
        "        prompt = sample[:prompt_length]\n",
        "        target = sample[prompt_length:]\n",
        "\n",
        "        generated = generate_continuation(\n",
        "            model,\n",
        "            tokenizer,\n",
        "            prompt,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        prompt_text = tokenizer.decode(prompt, skip_special_tokens=True)\n",
        "        target_text = tokenizer.decode(target, skip_special_tokens=True)\n",
        "        generated_text = tokenizer.decode(generated, skip_special_tokens=True)\n",
        "\n",
        "        tracker.add_sample(prompt_text, target_text, generated_text)\n",
        "\n",
        "def plot_results(trackers):\n",
        "    # Create figure with subplots\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "    # Plot training curves\n",
        "    plt.subplot(2, 2, 1)\n",
        "    for tracker in trackers:\n",
        "        label = f\"{tracker.model_size}-{tracker.tokenization_scheme}\"\n",
        "        plt.plot(tracker.train_perplexities, label=f\"{label} (train)\")\n",
        "        plt.plot(tracker.val_perplexities, label=f\"{label} (val)\", linestyle='--')\n",
        "    plt.title('Training Progress (Perplexity)')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Perplexity')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot learning rates\n",
        "    plt.subplot(2, 2, 2)\n",
        "    for tracker in trackers:\n",
        "        label = f\"{tracker.model_size}-{tracker.tokenization_scheme}\"\n",
        "        plt.plot(tracker.learning_rates, label=label)\n",
        "    plt.title('Learning Rate Schedule')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot final test metrics\n",
        "    plt.subplot(2, 2, 3)\n",
        "    labels = [f\"{t.model_size}-{t.tokenization_scheme}\" for t in trackers]\n",
        "    test_ppl = [t.test_metrics['perplexity'] for t in trackers]\n",
        "    bleu1 = [t.test_metrics['bleu_scores'][0] for t in trackers]\n",
        "\n",
        "    x = range(len(labels))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.bar([i - width/2 for i in x], test_ppl, width, label='Test Perplexity')\n",
        "    plt.bar([i + width/2 for i in x], bleu1, width, label='BLEU-1')\n",
        "    plt.xticks(x, labels, rotation=45)\n",
        "    plt.title('Test Metrics')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('experiment_results.png')\n",
        "    plt.close()\n",
        "\n",
        "# Run all experiments\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Run experiments\n",
        "    trackers = []\n",
        "    for model_size in ['small', 'large']:\n",
        "        for tokenization_scheme in ['char', 'subword']:\n",
        "            tracker = run_experiment(model_size, tokenization_scheme, data_splits, device)\n",
        "            trackers.append(tracker)\n",
        "\n",
        "    # Plot results\n",
        "    plot_results(trackers)\n",
        "\n",
        "    # Print final summary\n",
        "    print(\"\\nFinal Results Summary\")\n",
        "    print(\"=\" * 50)\n",
        "    for tracker in trackers:\n",
        "        print(f\"\\n{tracker.model_size.capitalize()} Model with {tracker.tokenization_scheme} tokenization:\")\n",
        "        print(f\"Test Perplexity: {tracker.test_metrics['perplexity']:.2f}\")\n",
        "        print(f\"BLEU-1: {tracker.test_metrics['bleu_scores'][0]:.4f}\")\n",
        "        print(f\"ROUGE-1 F1: {tracker.test_metrics['rouge_scores']['rouge-1']['f']:.4f}\")\n",
        "\n",
        "        print(\"\\nSample Generation:\")\n",
        "        sample = tracker.samples[0]  # Show first sample\n",
        "        print(f\"Prompt: {sample['prompt']}\")\n",
        "        print(f\"Target: {sample['target']}\")\n",
        "        print(f\"Generated: {sample['generated']}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0805f0a7161046f19b37af5cfd000e49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14e5085eb7bc42068fb09564d6eddf97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15e342761ed34fabb3f942b82c7b347f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bfb40c409024beb9bdc9df927bcccbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed4b18f94b23497682ea41c6d9b5dea8",
              "IPY_MODEL_4a8b9caf568b479bbf4eb4a0df87e014",
              "IPY_MODEL_b898c930cd4647d5ba0082dc617e3318"
            ],
            "layout": "IPY_MODEL_14e5085eb7bc42068fb09564d6eddf97"
          }
        },
        "1db71942daee448da32b058693363896": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23fbdadc7f644d608a16dfac3b6fd171": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2552d908d89a4872b23f1648ec230e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0ef8ed1d0b044cab77a393c0107384c",
              "IPY_MODEL_ea4373b493e7430fbd6b612402a32fcf",
              "IPY_MODEL_db7d1425cadf42b794080c32fba58f0c"
            ],
            "layout": "IPY_MODEL_f0ebcb73e82042a3b6d59168e44f64e4"
          }
        },
        "274616991c2f4af3a8bd9109050e99a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "281422a695d440089e86991f42290e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15e342761ed34fabb3f942b82c7b347f",
            "placeholder": "​",
            "style": "IPY_MODEL_dfabc6de82514719ac633c596a2e5e91",
            "value": "tokenizer.json: 100%"
          }
        },
        "4661738a0a85410aa7894a1c799c24b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70b96d397aa4a58a257fd17646ce809",
            "placeholder": "​",
            "style": "IPY_MODEL_23fbdadc7f644d608a16dfac3b6fd171",
            "value": "merges.txt: 100%"
          }
        },
        "47f2b69b378d471ba6cc3e912200ca13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49692fc296804c2c88f92b8aad815537": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ab7efb9b6c9462abac157186cf7068c",
              "IPY_MODEL_70a09e13879549c390b7dbeb3e3487ad",
              "IPY_MODEL_edd1f8b89a1e4845b1e0f73211de035a"
            ],
            "layout": "IPY_MODEL_76f9c0adc03146cb9dc12b30d97d8fd1"
          }
        },
        "4a8b9caf568b479bbf4eb4a0df87e014": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae0542ea8ab445558f442971d933ffd7",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea1b741c7b364c7cac8234fabb8c2756",
            "value": 26
          }
        },
        "5545c99f46c848eba58b4bfe74ad3ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "578f6988519b464ba4e69dc8cd0786a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47f2b69b378d471ba6cc3e912200ca13",
            "placeholder": "​",
            "style": "IPY_MODEL_6e3010afc3dc4cfab4a03a852fff3a39",
            "value": " 456k/456k [00:00&lt;00:00, 2.72MB/s]"
          }
        },
        "62b77e7531184a5ca453e5691b0fd4fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "662c7380cf1b4ec6afe89603f5860098": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69fcd57816604bd6a6457e5f7f6e72d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ab7efb9b6c9462abac157186cf7068c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_274616991c2f4af3a8bd9109050e99a0",
            "placeholder": "​",
            "style": "IPY_MODEL_69fcd57816604bd6a6457e5f7f6e72d4",
            "value": "config.json: 100%"
          }
        },
        "6b4852e6744c44699c9849bc683e1d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4661738a0a85410aa7894a1c799c24b6",
              "IPY_MODEL_ddb1d12558ef41beb157fe7a0b1a4718",
              "IPY_MODEL_578f6988519b464ba4e69dc8cd0786a6"
            ],
            "layout": "IPY_MODEL_ccb75a5bfc3b4e359ceb47001409b9c2"
          }
        },
        "6e3010afc3dc4cfab4a03a852fff3a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70310115250447e7a9f049fe77ee55c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70a09e13879549c390b7dbeb3e3487ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8186436a2854485d8229277842d350fc",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffbab30a25de4c948fb751d63e7aaba0",
            "value": 665
          }
        },
        "73e50455ebbb460c9e4285783efa3e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76f9c0adc03146cb9dc12b30d97d8fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8186436a2854485d8229277842d350fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89cf99a8752a48459c5f57b0d04da7b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "911d90b4516d42f8be7d18eaa4681221": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cfe8ab1baa640a1a252262b83dd2944": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_281422a695d440089e86991f42290e1c",
              "IPY_MODEL_e8cf9a477a3c418cbe9aa75b242e9ecc",
              "IPY_MODEL_a6d1745ec3584d54a26c3388a6f78158"
            ],
            "layout": "IPY_MODEL_62b77e7531184a5ca453e5691b0fd4fe"
          }
        },
        "a2f04bf75ffa442ea133802d2b7b6cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6d1745ec3584d54a26c3388a6f78158": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6509a2481a44b8b9e423e9c0c3b68a5",
            "placeholder": "​",
            "style": "IPY_MODEL_da08129348b14025a8bc4200bf128d93",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 8.07MB/s]"
          }
        },
        "ae0542ea8ab445558f442971d933ffd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0ef8ed1d0b044cab77a393c0107384c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0805f0a7161046f19b37af5cfd000e49",
            "placeholder": "​",
            "style": "IPY_MODEL_e97efd1c11864bdc8f514ef5ee51edc5",
            "value": "vocab.json: 100%"
          }
        },
        "b70b96d397aa4a58a257fd17646ce809": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b898c930cd4647d5ba0082dc617e3318": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9abdb81beb44753b9fcec84295ac7f9",
            "placeholder": "​",
            "style": "IPY_MODEL_70310115250447e7a9f049fe77ee55c5",
            "value": " 26.0/26.0 [00:00&lt;00:00, 697B/s]"
          }
        },
        "c9abdb81beb44753b9fcec84295ac7f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccb75a5bfc3b4e359ceb47001409b9c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d56f2fbec7194d6a9f4b72a256defe88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7e954fd16894e56a082aba9e282c814": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da08129348b14025a8bc4200bf128d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db7d1425cadf42b794080c32fba58f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89cf99a8752a48459c5f57b0d04da7b1",
            "placeholder": "​",
            "style": "IPY_MODEL_a2f04bf75ffa442ea133802d2b7b6cae",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 10.5MB/s]"
          }
        },
        "ddb1d12558ef41beb157fe7a0b1a4718": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d56f2fbec7194d6a9f4b72a256defe88",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2878069f9284d18b6a6e8a4429385ce",
            "value": 456318
          }
        },
        "dfabc6de82514719ac633c596a2e5e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6509a2481a44b8b9e423e9c0c3b68a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8cf9a477a3c418cbe9aa75b242e9ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc0083b0f41e402b9c1f2f7cd7da89c4",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5545c99f46c848eba58b4bfe74ad3ee3",
            "value": 1355256
          }
        },
        "e97efd1c11864bdc8f514ef5ee51edc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea1b741c7b364c7cac8234fabb8c2756": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea4373b493e7430fbd6b612402a32fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb4945df3ac44de49fec70e6e361c345",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_662c7380cf1b4ec6afe89603f5860098",
            "value": 1042301
          }
        },
        "eb4945df3ac44de49fec70e6e361c345": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed4b18f94b23497682ea41c6d9b5dea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1db71942daee448da32b058693363896",
            "placeholder": "​",
            "style": "IPY_MODEL_911d90b4516d42f8be7d18eaa4681221",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "edd1f8b89a1e4845b1e0f73211de035a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7e954fd16894e56a082aba9e282c814",
            "placeholder": "​",
            "style": "IPY_MODEL_73e50455ebbb460c9e4285783efa3e24",
            "value": " 665/665 [00:00&lt;00:00, 15.9kB/s]"
          }
        },
        "f0ebcb73e82042a3b6d59168e44f64e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2878069f9284d18b6a6e8a4429385ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc0083b0f41e402b9c1f2f7cd7da89c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffbab30a25de4c948fb751d63e7aaba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
